{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 5.1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Набор данных тут: https://github.com/sismetanin/rureviews, также есть в папке [Data](https://drive.google.com/drive/folders/1YAMe7MiTxA-RSSd8Ex2p-L0Dspe6Gs4L). Те, кто предпочитает работать с английским языком, могут использовать набор данных `sms_spam`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Применим полученные навыки и решим задачу анализа тональности отзывов.\n",
    "\n",
    "Нужно повторить весь пайплайн от сырых текстов до получения обученной модели.\n",
    "\n",
    "Обязательные шаги предобработки:\n",
    "1. токенизация\n",
    "2. приведение к нижнему регистру\n",
    "3. удаление стоп-слов\n",
    "4. лемматизация\n",
    "5. векторизация (с настройкой гиперпараметров)\n",
    "6. построение модели\n",
    "7. оценка качества модели\n",
    "\n",
    "Обязательно использование векторайзеров:\n",
    "1. мешок n-грамм (диапазон для n подбирайте самостоятельно, запрещено использовать только униграммы).\n",
    "2. tf-idf ((диапазон для n подбирайте самостоятельно, также нужно подбирать параметры max_df, min_df, max_features)\n",
    "3. символьные n-граммы (диапазон для n подбирайте самостоятельно)\n",
    "\n",
    "В качестве классификатора нужно использовать наивный байесовский классификатор.\n",
    "\n",
    "Для сравнения векторайзеров между собой используйте precision, recall, f1-score и accuracy. Для этого сформируйте датафрейм, в котором в строках будут разные векторайзеры, а в столбцах разные метрики качества, а в  ячейках будут значения этих метрик для соответсвующих векторайзеров."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ashee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ashee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              review sentiment\n0  качество плохое пошив ужасный (горловина напер...  negative\n1  Товар отдали другому человеку, я не получила п...  negative\n2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n3  товар не пришел, продавец продлил защиту без м...  negative\n4      Кофточка голая синтетика, носить не возможно.  negative",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>качество плохое пошив ужасный (горловина напер...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Товар отдали другому человеку, я не получила п...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>товар не пришел, продавец продлил защиту без м...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Кофточка голая синтетика, носить не возможно.</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"women-clothing-accessories.3-class.balanced.csv\", sep=\"\\t\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "negative    30000\nneautral    30000\npositive    30000\nName: sentiment, dtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              review sentiment  \\\n0  качество плохое пошив ужасный (горловина напер...  negative   \n1  Товар отдали другому человеку, я не получила п...  negative   \n2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative   \n3  товар не пришел, продавец продлил защиту без м...  negative   \n4      Кофточка голая синтетика, носить не возможно.  negative   \n\n                                              tokens  \n0  [качество, плохое, пошив, ужасный, (, горловин...  \n1  [Товар, отдали, другому, человеку, ,, я, не, п...  \n2  [Ужасная, синтетика, !, Тонкая, ,, ничего, общ...  \n3  [товар, не, пришел, ,, продавец, продлил, защи...  \n4  [Кофточка, голая, синтетика, ,, носить, не, во...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>качество плохое пошив ужасный (горловина напер...</td>\n      <td>negative</td>\n      <td>[качество, плохое, пошив, ужасный, (, горловин...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Товар отдали другому человеку, я не получила п...</td>\n      <td>negative</td>\n      <td>[Товар, отдали, другому, человеку, ,, я, не, п...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n      <td>negative</td>\n      <td>[Ужасная, синтетика, !, Тонкая, ,, ничего, общ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>товар не пришел, продавец продлил защиту без м...</td>\n      <td>negative</td>\n      <td>[товар, не, пришел, ,, продавец, продлил, защи...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Кофточка голая синтетика, носить не возможно.</td>\n      <td>negative</td>\n      <td>[Кофточка, голая, синтетика, ,, носить, не, во...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['review'].transform(word_tokenize)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Приведение к нижнему регистру"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0    [качество, плохое, пошив, ужасный, (, горловин...\n1    [товар, отдали, другому, человеку, ,, я, не, п...\n2    [ужасная, синтетика, !, тонкая, ,, ничего, общ...\n3    [товар, не, пришел, ,, продавец, продлил, защи...\n4    [кофточка, голая, синтетика, ,, носить, не, во...\nName: tokens, dtype: object"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['tokens'].apply(lambda x: list(map(lambda y: y.lower(), x)))\n",
    "df['tokens'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Удаление стоп-слов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def remove_sth(series, for_remove):\n",
    "    return series.apply(lambda x: list(filter(lambda y: y not in for_remove, x)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0    [качество, плохое, пошив, ужасный, горловина, ...\n1    [товар, отдали, другому, человеку, я, не, полу...\n2    [ужасная, синтетика, тонкая, ничего, общего, с...\n3    [товар, не, пришел, продавец, продлил, защиту,...\n4    [кофточка, голая, синтетика, носить, не, возмо...\nName: tokens, dtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = remove_sth(df['tokens'], string.punctuation)\n",
    "df['tokens'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Удаление стоп-слов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian')\n",
    "df['tokens']=remove_sth(df['tokens'], noise)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0    [качество, плохой, пошив, ужасный, горловина, ...\n1    [товар, отдать, другой, человек, получить, пос...\n2    [ужасный, синтетик, тонкий, общий, представить...\n3    [товар, прийти, продавец, продлить, защита, мо...\n4        [кофточка, голый, синтетик, носить, возможно]\nName: tokens, dtype: object"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph_analyzer=MorphAnalyzer()\n",
    "df['tokens']=df['tokens'].apply(lambda x: list(map(lambda y: morph_analyzer.parse(y)[0].normal_form, x)))\n",
    "df['tokens'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Векторизация (с настройкой гиперпараметров) и построение модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Необходимо использовать следующие веторизаторы:\n",
    "1. Мешок n-грамм (диапазон для n подбирайте самостоятельно, запрещено использовать только униграммы).\n",
    "2. TF-IDF (диапазон для n подбирайте самостоятельно, также нужно подбирать параметры max_df, min_df, max_features)\n",
    "3. Символьные n-граммы (диапазон для n подбирайте самостоятельно)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0    качество плохой пошив ужасный горловина напере...\n1    товар отдать другой человек получить посылка л...\n2    ужасный синтетик тонкий общий представить карт...\n3    товар прийти продавец продлить защита мой согл...\n4              кофточка голый синтетик носить возможно\nName: strings, dtype: object"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['strings'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "df['strings'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.strings, df.sentiment, train_size=0.66, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Count vectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n                ('classificator', MultinomialNB())])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([(\"vectorizer\", CountVectorizer()),(\"classificator\", MultinomialNB())])\n",
    "cv = GridSearchCV(pipeline, param_grid={'vectorizer__ngram_range': [(1, i) for i in range(2, 10)]})\n",
    "cv.fit(X_train, y_train)\n",
    "cv.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.61      0.63      0.62     10328\n",
      "    negative       0.71      0.66      0.68     10126\n",
      "    positive       0.82      0.85      0.84     10146\n",
      "\n",
      "    accuracy                           0.71     30600\n",
      "   macro avg       0.71      0.71      0.71     30600\n",
      "weighted avg       0.71      0.71      0.71     30600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, cv.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('vectorizer',\n                 TfidfVectorizer(max_df=0.5, min_df=0, ngram_range=(1, 2))),\n                ('classificator', MultinomialNB())])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline1=Pipeline([(\"vectorizer\", TfidfVectorizer()),(\"classificator\", MultinomialNB())])\n",
    "cv1 = GridSearchCV(pipeline1, param_grid={\n",
    "    \"vectorizer__max_df\": (0.5, 0.75, 0.95),\n",
    "    \"vectorizer__min_df\": (0, 0.01, 0.1, 0.25),\n",
    "    'vectorizer__max_features': (None, 1000, 5000, 10000),\n",
    "    \"vectorizer__ngram_range\": ((1, 2), (1, 3))\n",
    "})\n",
    "cv1.fit(X_train, y_train)\n",
    "cv1.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.61      0.63      0.62     10328\n",
      "    negative       0.71      0.66      0.68     10126\n",
      "    positive       0.82      0.86      0.84     10146\n",
      "\n",
      "    accuracy                           0.71     30600\n",
      "   macro avg       0.71      0.71      0.71     30600\n",
      "weighted avg       0.71      0.71      0.71     30600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, cv1.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Char vectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('vectorizer',\n                 CountVectorizer(analyzer='char', ngram_range=(5, 7))),\n                ('classificator', MultinomialNB())])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2=Pipeline([(\"vectorizer\", CountVectorizer(analyzer='char')),(\"classificator\", MultinomialNB())])\n",
    "cv2 = GridSearchCV(pipeline2, param_grid={\"vectorizer__ngram_range\": [(3,4), (5,7), (9,15),(16,17)]})\n",
    "cv2.fit(X_train, y_train)\n",
    "cv2.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.59      0.66      0.62     10328\n",
      "    negative       0.71      0.63      0.66     10126\n",
      "    positive       0.83      0.83      0.83     10146\n",
      "\n",
      "    accuracy                           0.71     30600\n",
      "   macro avg       0.71      0.71      0.71     30600\n",
      "weighted avg       0.71      0.71      0.71     30600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, cv2.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def get_scores(models, X_test, y_test, row_names):\n",
    "    values=[]\n",
    "    for model in models:\n",
    "        precision = precision_score(y_test, model.predict(X_test), average='weighted')\n",
    "        recall = recall_score(y_test, model.predict(X_test), average='weighted')\n",
    "        f1 = f1_score(y_test, model.predict(X_test), average='weighted')\n",
    "        accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "        values.append([precision,recall,f1,accuracy])\n",
    "    return pd.DataFrame(values, columns=['precision', 'recall', 'f1', 'accuracy'], index=row_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall        f1  accuracy\n",
      "Count vectorizer   0.712426  0.712451  0.711975  0.712451\n",
      "TF-IDF             0.713018  0.714020  0.712972  0.714020\n",
      "Char vectorizer    0.709840  0.705033  0.706006  0.705033\n"
     ]
    }
   ],
   "source": [
    "print(get_scores([cv, cv1, cv2], X_test, y_test, ['Count vectorizer', 'TF-IDF', 'Char vectorizer']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как мы видим, все три модели показали примерно одинаковый результат c точностью порядка 70-71%."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 5.2 Регулярные выражения"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### findall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ne', 're', 'ha', 'sa', 'be', 'pa', 'wr', 'pa', 'ga', 'mu', 'po']\n"
     ]
    }
   ],
   "source": [
    "random_words = 'neoclassical resolute hairdressing salon beauty parlour wrapping paper gardenia multicereal porridge'\n",
    "print(re.findall(r'\\b[a-zA-Z]{2}', random_words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neoclassical resolute', 'hairdressing salon', 'beauty. parlour wrapping. paper gardenia. multicereal porridge']\n"
     ]
    }
   ],
   "source": [
    "random_sentence = 'neoclassical resolute. hairdressing salon. beauty. parlour wrapping. paper gardenia. multicereal porridge'\n",
    "print(re.split(r'\\. ', random_sentence, maxsplit=2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание**: напишите регулярное выражение, которое позволит заменить все цифры в строке на \"DIG\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some phone number: DIG-DIGDIGDIG-DIGDIGDIG-DIGDIG-DIGDIG\n"
     ]
    }
   ],
   "source": [
    "digit_string = 'Some phone number: 8-921-887-39-20'\n",
    "print(re.sub('\\d', 'DIG', digit_string))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание**: напишите  регулярное выражение, которое позволит убрать url из строки."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit my github: URL\n"
     ]
    }
   ],
   "source": [
    "url = 'Visit my github: https://github.com/imashevchenko'\n",
    "regex = r'(https://)?[\\w\\.-]+\\.\\w{2,3}(/[\\w-]*(\\.[\\w-]+)?)*'\n",
    "\n",
    "print(re.sub(regex, 'URL', url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### compile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "['neoclassical',\n 'resolute',\n 'hairdressing',\n 'salon',\n 'beauty',\n 'parlour',\n 'wrapping',\n 'paper',\n 'gardenia',\n 'multicereal',\n 'porridge']"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentence = 'neoclassical resolute hairdressing salon beauty parlour wrapping paper gardenia multicereal porridge'\n",
    "regex_obj = re.compile(r'\\w{4,}')\n",
    "regex_obj.findall(random_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "['@gmail.com', '@gmail.com', '@yandex.ru']"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_string = 'shevchenkoav2002@gmail.com, vitars@gmail.com, smth.smth@yandex.ru'\n",
    "regex_obj_2 = re.compile(r'@\\w+\\.\\w+')\n",
    "regex_obj_2.findall(email_string)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}